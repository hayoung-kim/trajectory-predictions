{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from expm.pytorch_expm.expm_taylor import expm_taylor\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import glob\n",
    "from dataset import NusceneDataset\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from visualizer import plot_to_image, plot_single_batch, plot_predictions_single_batch\n",
    "\n",
    "# notebook\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "LOAD_TRAINED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 24 14:26:52 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8    32W / 280W |    175MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8     6W / 280W |      1MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:67:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     9W / 280W |      1MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:68:00.0  On |                  N/A |\n",
      "|  0%   32C    P8     5W / 280W |    330MiB / 24217MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     20820      C   /usr/bin/python3                             163MiB |\n",
      "|    3      1535      G   /usr/lib/xorg/Xorg                            14MiB |\n",
      "|    3      1651      G   /usr/bin/gnome-shell                          50MiB |\n",
      "|    3      1849      G   /usr/lib/xorg/Xorg                           127MiB |\n",
      "|    3      1978      G   /usr/bin/gnome-shell                         107MiB |\n",
      "|    3      5216      G   /opt/teamviewer/tv_bin/TeamViewer             24MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "# print ('Current cuda device ', torch.cuda.current_device())\n",
    "# print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# # GPU 할당 변경하기\n",
    "# GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "# print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "# #Additional Infos\n",
    "# if device.type == 'cuda':\n",
    "#     print(torch.cuda.get_device_name(GPU_NUM))\n",
    "#     print('Memory Usage:')\n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8324)\n",
    "torch.cuda.manual_seed(8324)\n",
    "np.random.seed(8324)\n",
    "\n",
    "B, A, T, D = 8, 5, 20, 2\n",
    "\n",
    "dataset_path = \"/home/mmc-server2/data/serialized_nuscenes\"\n",
    "max_data = int(1024)\n",
    "train_dills = np.asarray(sorted(glob.glob(dataset_path + \"/train/sdata*\")))[:max_data]\n",
    "\n",
    "train_dataset = NusceneDataset(train_dills, max_A=5)\n",
    "dataloader = DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # static\n",
    "        self.past_rnn = nn.GRU(2, hidden_size=128, num_layers=1, bias=True, batch_first=True)\n",
    "        self.social_mlp = nn.Sequential(\n",
    "            nn.Linear(8, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 100)    \n",
    "        )\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(5, 32, 3, 1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 3, 1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 3, 1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 3, 1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 12, 3, 1, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # dynamic loop\n",
    "        self.future_rnn = nn.GRUCell(100+256+10+12*5, 100)  # social_mlp + past * 2 + A*2 + CA\n",
    "        self.future_mlp = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.past_rnn.cuda()\n",
    "            self.cnn.cuda()\n",
    "            self.social_mlp.cuda()\n",
    "            self.future_rnn.cuda()\n",
    "            self.future_mlp.cuda()\n",
    "        \n",
    "    def forward(self, player_past, other_pasts, overhead_sdt_features, z):\n",
    "        # dataset\n",
    "        pasts = torch.cat((torch.unsqueeze(player_past, dim=1), other_pasts), dim=1)\n",
    "        agent_past_list = torch.split(pasts, split_size_or_sections=1, dim=1)\n",
    "        \n",
    "        # forward 1: static\n",
    "        last_hiddens = []\n",
    "        for past in agent_past_list:\n",
    "            past = torch.squeeze(past, dim=1)\n",
    "            _, last_hidden = self.past_rnn(past)\n",
    "            last_hiddens.append(last_hidden)  # (1, B, hidden)\n",
    "\n",
    "        alpha1 = torch.cat(last_hiddens, dim=0)  # (A, B, hidden)\n",
    "\n",
    "        alpha2_list = []\n",
    "        for last_hidden in last_hiddens:\n",
    "            other_sum = torch.sum(alpha1, dim=0, keepdim=True) - last_hidden  # (1, B, hidden)\n",
    "            alpha2 = torch.cat((last_hidden, other_sum), dim=2)  # (1, B, hidden*2)\n",
    "            alpha2 = torch.squeeze(alpha2, dim=0)  # (B, hidden*2)\n",
    "            alpha2_list.append(alpha2)\n",
    "            \n",
    "        # cnn\n",
    "        map_features = self.cnn(overhead_sdt_features)\n",
    "        \n",
    "            \n",
    "        # forward 2: dynamic loop\n",
    "        future_rnn_hs = [None] * 5\n",
    "\n",
    "        B, A, _, _ = pasts.shape\n",
    "        T = 20\n",
    "\n",
    "        currents = pasts[..., -1, :]\n",
    "        previous = pasts[..., -2, :]\n",
    "\n",
    "        nexts_list  = []\n",
    "        sigmas_list = []\n",
    "\n",
    "        for t in range(T):\n",
    "            a_next_list = []\n",
    "            a_sigma_list = []\n",
    "            \n",
    "            # social map feature 구하는 방법이 구림: 순서 바뀌면 네트워크 결과 바뀜\n",
    "            PIXELS_PER_METER = 2.0\n",
    "            H = 200\n",
    "            W = 200\n",
    "            currents_in_grid = H // 2 + currents * PIXELS_PER_METER  # (B, A, 2)\n",
    "            currents_in_grid = currents_in_grid / H  # normalize to between 0 and 1\n",
    "            currents_in_grid = currents_in_grid * 2 - 1.0  # normalize to between -1 and 1\n",
    "            \n",
    "            currents_in_grid = currents_in_grid.unsqueeze(2)  # (B, A, 1, D=2)\n",
    "            interp_out = nn.functional.grid_sample(map_features, currents_in_grid, align_corners=True)  # (B, C=8, A, 1)\n",
    "            social_map_features = torch.squeeze(interp_out, dim=-1)  # (B, C=8, A)\n",
    "            social_map_features = torch.flatten(social_map_features, start_dim=1, end_dim=2)  # (B, CA)\n",
    "            \n",
    "            for a in range(A):\n",
    "                a_current  = currents[:, a, :]\n",
    "                a_previous = previous[:, a, :] \n",
    "\n",
    "                other_currents = [currents[:, j, :] for j in range(A) if j!=a]\n",
    "\n",
    "                displacements = [a_current - oc for oc in other_currents]\n",
    "                displacements = torch.stack(displacements, dim=1)  # (B, A, 2)\n",
    "\n",
    "                displacements_flatten = torch.flatten(displacements, start_dim=1)\n",
    "                social_feature = self.social_mlp(displacements_flatten)\n",
    "                currents_flatten = torch.flatten(currents, start_dim=1)\n",
    "\n",
    "#                 joint_feature = torch.cat((alpha2_list[a], social_feature, currents_flatten), dim=1)\n",
    "                joint_feature = torch.cat((alpha2_list[a], social_feature, currents_flatten, social_map_features), dim=1)\n",
    "\n",
    "                h = self.future_rnn(joint_feature, future_rnn_hs[a])\n",
    "                future_rnn_hs[a] = h\n",
    "\n",
    "                out = self.future_mlp(h)\n",
    "                m_at, zeta_at = out[:, :2], out[:, 2:6]\n",
    "                zeta_at = torch.reshape(zeta_at, (-1, 2, 2))\n",
    "                sigma_at = expm_taylor(zeta_at + torch.transpose(zeta_at, 1, 2))\n",
    "\n",
    "                z_at = z[:, a, t]\n",
    "\n",
    "                sigma_prod_z_at = torch.squeeze(torch.matmul(sigma_at, z_at), dim=2)\n",
    "                a_next = 2 * a_current - a_previous + m_at + sigma_prod_z_at\n",
    "\n",
    "                a_next_list.append(a_next)\n",
    "                a_sigma_list.append(sigma_at)\n",
    "\n",
    "            # preparing next t\n",
    "            nexts = torch.stack(a_next_list, dim=1)\n",
    "            sigmas = torch.stack(a_sigma_list, dim=1)\n",
    "            nexts_list.append(nexts)\n",
    "            sigmas_list.append(sigmas)\n",
    "\n",
    "            previous = currents\n",
    "            currents = nexts\n",
    "\n",
    "        # q_distribution\n",
    "        prediction_mus  = torch.stack(nexts_list, dim=2)\n",
    "        prediction_covs = torch.stack(sigmas_list, dim=2)\n",
    "        \n",
    "        return prediction_mus, prediction_covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_summaries(model):\n",
    "    module_names = []\n",
    "    for param in model.named_parameters():\n",
    "        param_name, param_val = param\n",
    "        names = param_name.split('.')\n",
    "\n",
    "        module_name = names[0]\n",
    "        if module_name not in module_names:\n",
    "            module_names.append(module_name)\n",
    "\n",
    "    model_summary = dict()\n",
    "    for module_name in module_names:\n",
    "        model_summary['model/' + module_name + '/value/' + 'weights'] = []\n",
    "        model_summary['model/' + module_name + '/value/' + 'biases'] = []\n",
    "        model_summary['model/' + module_name + '/grad/' + 'weights'] = []\n",
    "        model_summary['model/' + module_name + '/grad/' + 'biases'] = []\n",
    "\n",
    "    for param in model.named_parameters():\n",
    "        param_name, param_val = param\n",
    "        names = param_name.split('.')\n",
    "\n",
    "        module_name = names[0]\n",
    "\n",
    "        if 'weight' in names[-1]:\n",
    "            model_summary['model/' + module_name + '/value/' + 'weights'].append(param_val.view(-1))\n",
    "            model_summary['model/' + module_name + '/grad/' + 'weights'].append(param_val.grad.view(-1))\n",
    "        elif 'bias' in names[-1]:\n",
    "            model_summary['model/' + module_name + '/value/' + 'biases'].append(param_val.view(-1))\n",
    "            model_summary['model/' + module_name + '/grad/' + 'biases'].append(param_val.grad.view(-1))\n",
    "\n",
    "    scalar_model_summary = dict()\n",
    "    for key, val in model_summary.items():\n",
    "        scalar_model_summary[key] = torch.norm(torch.cat([v for v in val]))\n",
    "    return model_summary, scalar_model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_TRAINED:\n",
    "    trained = torch.load(\"./log/trainset_all_b8_wobn_2020-06-21-15-17/model.pt\")\n",
    "    trained.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "if LOAD_TRAINED:\n",
    "    model.load_state_dict(trained['model_state_dict'])\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "if LOAD_TRAINED:\n",
    "    optimizer.load_state_dict(trained['optimizer_state_dict'])\n",
    "    optimizer.lr = 3e-5\n",
    "    logdir = f\"./log/trainset_all_b8_wobn_2020-06-21-15-17\"\n",
    "else:\n",
    "    logdir = f\"./log/trainset_all_b8_wobn_{datetime.now():%Y-%m-%d-%H-%M}\"\n",
    "\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model_summary(model, writer):\n",
    "    _, scalar_model_summaries = get_model_summaries(model)\n",
    "    for key, val in scalar_model_summaries.items():\n",
    "        writer.add_scalar(key, val, global_iterations)\n",
    "        \n",
    "    del scalar_model_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(model, dataloader):\n",
    "#     print('[*] evaluating ...')\n",
    "    losses, loss_poss = [], []\n",
    "    minADEs, minFDEs, miss_rate_2s = [], [], []\n",
    "    \n",
    "    model = model.eval()\n",
    "#     for i, data in enumerate(tqdm(dataloader, 0)):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        player_past           = data['player_past'].cuda()\n",
    "        other_pasts           = data['other_pasts'].cuda()\n",
    "        overhead_sdt_features = data['overhead_sdt_features'].cuda()\n",
    "\n",
    "        B = player_past.shape[0]\n",
    "        z = torch.randn((B, A, T, 2, 1)).cuda()\n",
    "\n",
    "        # model\n",
    "        with torch.no_grad():\n",
    "            mus, covs = model(player_past, other_pasts, overhead_sdt_features, z)\n",
    "\n",
    "            # q distribution\n",
    "            q_dist = MultivariateNormal(loc=mus, covariance_matrix=covs)\n",
    "\n",
    "            # target distribution (p)\n",
    "            player_future = data['player_expert'].cuda()\n",
    "            other_futures = data['other_experts'].cuda()\n",
    "            futures       = torch.cat((torch.unsqueeze(player_future, dim=1), other_futures), dim=1)\n",
    "            p_cov         = 0.01 * torch.eye(2)[None, None, None, ...].repeat(B, A, T, 1, 1).cuda()\n",
    "            p_dist        = MultivariateNormal(loc=futures, covariance_matrix=p_cov)\n",
    "\n",
    "            # cross entropy loss with noise\n",
    "            p_samples = p_dist.sample(sample_shape=[12])\n",
    "            loss      = -q_dist.log_prob(p_samples).mean()\n",
    "            loss_lb   = -p_dist.log_prob(p_samples).mean()\n",
    "            loss_pos  = loss - loss_lb\n",
    "        \n",
    "        # some metrics\n",
    "        q_dist_samples = q_dist.sample(sample_shape=[12])\n",
    "        _futures = torch.unsqueeze(futures, dim=0)\n",
    "        \n",
    "        err = q_dist_samples - _futures\n",
    "        norm2 = torch.norm(err, dim=-1)\n",
    "        \n",
    "        ADE = torch.mean(norm2, dim=-1)\n",
    "        minADE = torch.min(ADE, dim=0)\n",
    "        minADE_avg_over_agent = torch.mean(minADE.values, dim=-1)\n",
    "        minADE_avg = torch.mean(minADE_avg_over_agent)\n",
    "        \n",
    "        fde = err[..., -1, :]\n",
    "        fde_L2 = torch.norm(fde, dim=-1)\n",
    "        fde_L2_per_sample = torch.reshape(fde_L2, (-1, B, 5))\n",
    "        minFDE = torch.min(fde_L2_per_sample, dim=0)\n",
    "        minFDE_avg_over_agent = torch.mean(minFDE.values, dim=-1)\n",
    "        minFDE_avg = torch.mean(minFDE_avg_over_agent)\n",
    "        \n",
    "        miss_2 = (norm2 > 2.0)\n",
    "        miss_rate_2 = torch.mean(miss_2, dtype=torch.float32)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        loss_poss.append(loss_pos)\n",
    "        \n",
    "        minADEs.append(minADE_avg)\n",
    "        minFDEs.append(minFDE_avg)\n",
    "        miss_rate_2s.append(miss_rate_2)\n",
    "        \n",
    "        del loss, loss_pos, minADE_avg, minFDE_avg, miss_rate_2\n",
    "        del player_past, other_pasts, overhead_sdt_features, z, mus, covs, player_future, other_futures, futures\n",
    "    \n",
    "    loss = torch.Tensor(losses).mean()\n",
    "    loss_pos = torch.Tensor(loss_poss).mean()\n",
    "    minADE = torch.Tensor(minADEs).mean()\n",
    "    minFDE = torch.Tensor(minFDEs).mean()\n",
    "    miss_rate_2 = torch.Tensor(miss_rate_2s).mean()\n",
    "    \n",
    "    return loss, loss_pos, minADE, minFDE, miss_rate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predictions(model, dataset, dataset_idxs, global_iterations, loss, loss_pos, minADE, minFDE, miss_rate):\n",
    "    assert len(dataset_idxs) == 4\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        # dataset\n",
    "        player_past           = torch.cat([torch.Tensor(dataset[i]['player_past'][None]) for i in dataset_idxs], dim=0).cuda()\n",
    "        other_pasts           = torch.cat([torch.Tensor(dataset[i]['other_pasts'][None]) for i in dataset_idxs], dim=0).cuda()\n",
    "        overhead_sdt_features = torch.cat([torch.Tensor(dataset[i]['overhead_sdt_features'][None]) for i in dataset_idxs], dim=0).cuda()\n",
    "\n",
    "        player_future = torch.cat([torch.Tensor(dataset[i]['player_expert'][None]) for i in dataset_idxs], dim=0).cuda()\n",
    "        other_futures = torch.cat([torch.Tensor(dataset[i]['other_experts'][None]) for i in dataset_idxs], dim=0).cuda()\n",
    "\n",
    "        B = player_past.shape[0]\n",
    "        z = torch.randn((B, A, T, 2, 1)).cuda()\n",
    "\n",
    "        # model\n",
    "        mus, covs = model(player_past, other_pasts, overhead_sdt_features, z)\n",
    "\n",
    "        # q distribution\n",
    "        q_dist = MultivariateNormal(loc=mus, covariance_matrix=covs)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "    ax = ax.reshape(-1)\n",
    "    q_dist_samples = q_dist.sample(sample_shape=[7])\n",
    "    for b in range(B):\n",
    "        fig, ax[b] = plot_single_batch(\n",
    "            player_past[b].cpu(), \n",
    "            other_pasts[b].cpu(), \n",
    "            player_future[b].cpu(), \n",
    "            other_futures[b].cpu(), \n",
    "            fig, ax[b]\n",
    "        )\n",
    "\n",
    "        fig, ax[b] = plot_predictions_single_batch(\n",
    "            fig, ax[b], q_dist_samples[:, b, ...].cpu()\n",
    "        )\n",
    "\n",
    "        ax[b].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(f\"epoch={epoch:05d}, iter={global_iterations:07d} \\nHpq={loss:.3f}, Hp'q={loss_pos:.3f}, \\nminADE={minADE:.2f}, minFDE={minFDE:.3f}, \\nmiss_rate_2={miss_rate*100.0:.2f}%\", fontsize=24)\n",
    "    image = plot_to_image(fig)\n",
    "    \n",
    "    del player_past, other_pasts, overhead_sdt_features, player_future, other_futures, z, mus, covs\n",
    "    \n",
    "    del fig, ax\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26  14 131 306]\n"
     ]
    }
   ],
   "source": [
    "dataset_idxs = np.random.randint(0, len(train_dataset), 4)\n",
    "print(dataset_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=00000, iter=0000010, Hpq_positive=933.64, Hpq=931.87, minADE=28.61, minFDE=68.05, miss_rate_2=92.47%\n",
      "epoch=00000, iter=0000020, Hpq_positive=679.54, Hpq=677.78, minADE=22.64, minFDE=53.37, miss_rate_2=89.95%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c9a5920aae48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mglobal_iterations\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mglobal_iterations\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_minADE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_minFDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_miss_rate_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/all/Hpq_positive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/all/Hpq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-1d04ed7f7a35>\u001b[0m in \u001b[0;36mevaluate_dataset\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     for i, data in enumerate(tqdm(dataloader, 0)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mplayer_past\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'player_past'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mother_pasts\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'other_pasts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/play_torch/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = int(200000)\n",
    "A = 5\n",
    "T = 20\n",
    "\n",
    "if LOAD_TRAINED:\n",
    "    best_loss = trained['loss']\n",
    "    global_iterations = trained['global_iteractions']\n",
    "    epoch_start = trained['epoch']\n",
    "else:\n",
    "    best_loss = 10.0\n",
    "    global_iterations = 0\n",
    "    epoch_start = 0\n",
    "\n",
    "for epoch in range(epoch_start, MAX_EPOCHS):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        global_iterations += 1\n",
    "        \n",
    "        player_past           = data['player_past'].cuda()\n",
    "        other_pasts           = data['other_pasts'].cuda()\n",
    "        overhead_sdt_features = data['overhead_sdt_features'].cuda()\n",
    "\n",
    "        B = player_past.shape[0]\n",
    "        z = torch.randn((B, A, T, 2, 1)).cuda()\n",
    "\n",
    "        # model\n",
    "        model = model.train()\n",
    "        mus, covs = model(player_past, other_pasts, overhead_sdt_features, z)\n",
    "\n",
    "        # q distribution\n",
    "        q_dist = MultivariateNormal(loc=mus, covariance_matrix=covs)\n",
    "\n",
    "        # target distribution (p)\n",
    "        player_future = data['player_expert'].cuda()\n",
    "        other_futures = data['other_experts'].cuda()\n",
    "        futures       = torch.cat((torch.unsqueeze(player_future, dim=1), other_futures), dim=1)\n",
    "        p_cov         = 0.01 * torch.eye(2)[None, None, None, ...].repeat(B, A, T, 1, 1).cuda()\n",
    "        p_dist        = MultivariateNormal(loc=futures, covariance_matrix=p_cov)\n",
    "\n",
    "        # cross entropy loss with noised \n",
    "        p_samples = p_dist.sample(sample_shape=[12])\n",
    "        loss      = -q_dist.log_prob(p_samples).mean()\n",
    "        loss_lb   = -p_dist.log_prob(p_samples).mean()\n",
    "        loss_pos  = loss - loss_lb\n",
    "\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # write train information\n",
    "        writer.add_scalar(\"train/batch/Hpq_positive\", loss_pos, global_iterations)\n",
    "        \n",
    "        if (global_iterations % 10 == 0) and (global_iterations > 0):\n",
    "            write_model_summary(model, writer)\n",
    "        \n",
    "        if (global_iterations % 10 == 0) and (global_iterations > 0):\n",
    "            _loss, _loss_pos, _minADE, _minFDE, _miss_rate_2 = evaluate_dataset(model, train_test_dataloader)\n",
    "            writer.add_scalar(\"train/all/Hpq_positive\", _loss_pos, global_iterations)\n",
    "            writer.add_scalar(\"train/all/Hpq\", _loss, global_iterations)\n",
    "            writer.add_scalar(\"train/all/minADE\", _minADE, global_iterations)\n",
    "            writer.add_scalar(\"train/all/minFDE\", _minFDE, global_iterations)\n",
    "            writer.add_scalar(\"train/all/miss_rate_2\", _miss_rate_2*100.0, global_iterations)\n",
    "            print(f\"epoch={epoch:05d}, iter={global_iterations:07d}, Hpq_positive={_loss_pos:.2f}, Hpq={_loss:.2f}, minADE={_minADE:.2f}, minFDE={_minFDE:.2f}, miss_rate_2={_miss_rate_2*100.0:.2f}%\")\n",
    "            \n",
    "            if global_iterations % 100 == 0:\n",
    "                image = draw_predictions(\n",
    "                    model, train_dataset, dataset_idxs, global_iterations, _loss, _loss_pos, _minADE, _minFDE, _miss_rate_2)\n",
    "                writer.add_image('train_data', image, global_step=global_iterations, dataformats='HWC')\n",
    "                del image\n",
    "        \n",
    "            # save model\n",
    "            if _loss < best_loss:\n",
    "                best_loss = _loss\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'global_iteractions':global_iterations,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': _loss,\n",
    "                }, logdir + \"/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = name.split('.')\n",
    "if len(names) == 4: _, module_name, num, wb = names\n",
    "elif len(names) == 3: _, module_name, wb = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_samples = p_dist.sample(sample_shape=[12])\n",
    "loss = -q_dist.log_prob(p_samples).mean()\n",
    "-p_dist.log_prob(p_samples).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, val = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (torch)",
   "language": "python",
   "name": "play_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
